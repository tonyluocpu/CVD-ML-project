{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras_tuner as kt\n",
    "\n",
    "tf.config.threading.set_intra_op_parallelism_threads(64)  # Maximize intra-op parallelism across 64 CPUs\n",
    "tf.config.threading.set_inter_op_parallelism_threads(64)\n",
    "# Load the data\n",
    "X = pd.read_csv('X_imputed.csv')\n",
    "y = pd.read_csv('y_data.csv')\n",
    "\n",
    "# Replace missing values in y with NaN\n",
    "y = y.replace(\"?\", np.nan)  # If missing values are marked with \"?\" in the dataset\n",
    "y_numeric = y.drop(columns=['statecounty']) # Remove 'statecounty'\n",
    "# Normalize X (remove the 'statecounty' column)\n",
    "X_numeric = X.drop(columns=['statecounty'])  # Remove 'statecounty'\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_numeric), columns=X_numeric.columns)\n",
    "\n",
    "# Split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_numeric, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/multi_target_hyperparam_tuning/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Custom masked loss function to handle missing values in y\n",
    "def masked_loss(y_true, y_pred):\n",
    "    mask = tf.math.is_finite(y_true)  # Create a mask to ignore NaNs\n",
    "    y_true_masked = tf.where(mask, y_true, 0.0)  # Replace NaNs with 0.0 for loss calculation\n",
    "    y_pred_masked = tf.where(mask, y_pred, 0.0)\n",
    "    return tf.reduce_mean(tf.square(y_true_masked - y_pred_masked))\n",
    "\n",
    "def build_model(hp):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)))\n",
    "\n",
    "    # Tune the number of layers and units in each layer\n",
    "    for i in range(hp.Int('num_layers', 2, 3)):  # Narrow to between 2 and 3 layers\n",
    "        model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                                     min_value=128,\n",
    "                                                     max_value=256,  # Narrow units range\n",
    "                                                     step=64),\n",
    "                                        activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(hp.Float('dropout_' + str(i),\n",
    "                                                   min_value=0.2,\n",
    "                                                   max_value=0.4,\n",
    "                                                   step=0.1)))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(y_train.shape[1], activation='linear'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "                      hp.Float('learning_rate', 1e-4, 1e-3, sampling='log')),  # Narrow learning rate\n",
    "                  loss=masked_loss,\n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Hyperparameter tuning using  RandomSearch\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mae',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='multi_target_hyperparam_tuning',\n",
    "    max_consecutive_failed_trials=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 Complete [00h 00m 27s]\n",
      "val_mae: nan\n",
      "\n",
      "Best val_mae So Far: nan\n",
      "Total elapsed time: 00h 07m 37s\n",
      "\n",
      "Search: Running Trial #10\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "3                 |2                 |num_layers\n",
      "512               |320               |units_0\n",
      "0.2               |0.4               |dropout_0\n",
      "256               |512               |units_1\n",
      "0.4               |0.2               |dropout_1\n",
      "0.0028187         |0.00013819        |learning_rate\n",
      "512               |256               |units_2\n",
      "0.4               |0.3               |dropout_2\n",
      "192               |192               |units_3\n",
      "0.2               |0.2               |dropout_3\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/zmaggio/BigRed200/.local/lib/python3.9/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 17118.6348 - mae: nan - val_loss: 3148.8933 - val_mae: nan\n",
      "Epoch 2/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4334.0322 - mae: nan - val_loss: 2742.6292 - val_mae: nan\n",
      "Epoch 3/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5999.7681 - mae: nan - val_loss: 2592.3306 - val_mae: nan\n",
      "Epoch 4/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2955.0754 - mae: nan - val_loss: 2394.2944 - val_mae: nan\n",
      "Epoch 5/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3503.5994 - mae: nan - val_loss: 2250.2263 - val_mae: nan\n",
      "Epoch 6/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4064.9221 - mae: nan - val_loss: 2227.6384 - val_mae: nan\n",
      "Epoch 7/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2593.7339 - mae: nan - val_loss: 2249.3008 - val_mae: nan\n",
      "Epoch 8/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3740.0771 - mae: nan - val_loss: 2210.0642 - val_mae: nan\n",
      "Epoch 9/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4956.9082 - mae: nan - val_loss: 2066.0518 - val_mae: nan\n",
      "Epoch 10/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2195.4612 - mae: nan - val_loss: 2245.4827 - val_mae: nan\n",
      "Epoch 11/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7186.2402 - mae: nan - val_loss: 2183.5110 - val_mae: nan\n",
      "Epoch 12/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1919.8994 - mae: nan - val_loss: 2214.8818 - val_mae: nan\n",
      "Epoch 13/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4148.3823 - mae: nan - val_loss: 2153.4060 - val_mae: nan\n",
      "Epoch 14/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1922.4871 - mae: nan - val_loss: 2141.2209 - val_mae: nan\n",
      "Epoch 15/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2151.1995 - mae: nan - val_loss: 2548.8770 - val_mae: nan\n",
      "Epoch 16/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1811.0359 - mae: nan - val_loss: 2029.8024 - val_mae: nan\n",
      "Epoch 17/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2397.2668 - mae: nan - val_loss: 2210.2532 - val_mae: nan\n",
      "Epoch 18/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1593.0349 - mae: nan - val_loss: 2127.7637 - val_mae: nan\n",
      "Epoch 19/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3219.3760 - mae: nan - val_loss: 2239.7651 - val_mae: nan\n",
      "Epoch 20/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6358.7212 - mae: nan - val_loss: 2200.2927 - val_mae: nan\n",
      "Epoch 21/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5405.7397 - mae: nan - val_loss: 2264.7141 - val_mae: nan\n",
      "Epoch 22/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2147.5264 - mae: nan - val_loss: 2066.9939 - val_mae: nan\n",
      "Epoch 23/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1503.8251 - mae: nan - val_loss: 2259.1252 - val_mae: nan\n",
      "Epoch 24/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1984.5667 - mae: nan - val_loss: 2125.1812 - val_mae: nan\n",
      "Epoch 25/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1535.2826 - mae: nan - val_loss: 2102.8062 - val_mae: nan\n",
      "Epoch 26/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2081.6650 - mae: nan - val_loss: 2129.6704 - val_mae: nan\n",
      "Epoch 27/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1411.2249 - mae: nan - val_loss: 2045.9191 - val_mae: nan\n",
      "Epoch 28/50\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2009.7802 - mae: nan - val_loss: 2080.5422 - val_mae: nan\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, batch_size=64)\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the best model\n",
    "loss, mae = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Best Model Test Loss: {loss}, Test MAE: {mae}\")\n",
    "\n",
    "# Save the best model\n",
    "best_model.save('best_multi_target_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
